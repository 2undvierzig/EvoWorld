{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19343204-f9a3-4096-ab19-395825ac7f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m             agent\u001b[38;5;241m.\u001b[39mlearn(state, action, reward, next_state)\n\u001b[0;32m     98\u001b[0m             state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m--> 100\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Q-learning agent definition\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQLearningAgent\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[1], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(agent, env, episodes)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     94\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchoose_action(state)\n\u001b[1;32m---> 95\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m discretize(next_state)\n\u001b[0;32m     97\u001b[0m     agent\u001b[38;5;241m.\u001b[39mlearn(state, action, reward, next_state)\n",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m, in \u001b[0;36mRectangleMoveEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     60\u001b[0m params \u001b[38;5;241m=\u001b[39m mappings[action]\n\u001b[0;32m     61\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:5000/move_rectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, json\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m---> 62\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Get the new position (state) from the data\u001b[39;00m\n\u001b[0;32m     65\u001b[0m new_position \u001b[38;5;241m=\u001b[39m [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_x\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_y\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, jsonify\n",
    "from flask_socketio import SocketIO, emit\n",
    "import gym\n",
    "from gym import spaces\n",
    "import math\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Q-learning agent definition\n",
    "class QLearningAgent:\n",
    "    def __init__(self, n_actions, n_states, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.n_actions = n_actions\n",
    "        self.q_table = np.zeros((n_states, n_states, n_actions))\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state[0], state[1]])\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        predict = self.q_table[state[0], state[1], action]\n",
    "        target = reward + self.gamma * np.max(self.q_table[next_state[0], next_state[1]])\n",
    "        self.q_table[state[0], state[1], action] += self.alpha * (target - predict)\n",
    "\n",
    "# Discretize the environment\n",
    "def discretize(state, bins=50):\n",
    "    return tuple((np.array(state) * bins // 500).astype(int))\n",
    "\n",
    "class RectangleMoveEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(RectangleMoveEnv, self).__init__()\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Let's assume action space is discrete: 0: Up, 1: Down, 2: Left, 3: Right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # Define the observation space as the position of the rectangle. This is a simplification.\n",
    "        # You can expand this to include more features if needed.\n",
    "        self.observation_space = spaces.Box(low=0, high=500, shape=(2,), dtype=float)  # Assuming canvas size of 500x500 for illustration\n",
    "\n",
    "    def reset(self):\n",
    "        # For simplicity, reset will return the rectangle to the center of the canvas\n",
    "        # This can be expanded to communicate with Flask server to get an actual reset position\n",
    "        return [250, 250]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Translate the action to the parameters of move_rectangle function\n",
    "        # For simplicity, let's assume fixed speed, distance, and angle based on the action\n",
    "        mappings = {\n",
    "            0: {'speed': 50, 'angle': 0, 'distance': 10},   # Up\n",
    "            1: {'speed': 50, 'angle': 180, 'distance': 10}, # Down\n",
    "            2: {'speed': 50, 'angle': 270, 'distance': 10}, # Left\n",
    "            3: {'speed': 50, 'angle': 90, 'distance': 10}   # Right\n",
    "        }\n",
    "\n",
    "        params = mappings[action]\n",
    "        response = requests.post('http://127.0.0.1:5000/move_rectangle', json=params)\n",
    "        data = response.json()\n",
    "\n",
    "        # Get the new position (state) from the data\n",
    "        new_position = [data['new_x'], data['new_y']]\n",
    "        \n",
    "        # Check border collision\n",
    "        border_hit_response = requests.get('http://127.0.0.1:5000/border_hit')\n",
    "        hit_data = border_hit_response.json()\n",
    "        done = hit_data['hit']\n",
    "\n",
    "        # Define reward. For simplicity, a negative reward if border is hit.\n",
    "        reward = -10 if done else 1\n",
    "\n",
    "        return new_position, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Optional method for visualization\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Initialize the Q-learning agent and the environment\n",
    "agent = QLearningAgent(n_actions=4, n_states=50)\n",
    "env = RectangleMoveEnv()\n",
    "\n",
    "# Train the agent on the environment\n",
    "def train(agent, env, episodes=1000):\n",
    "    for episode in range(episodes):\n",
    "        state = discretize(env.reset())\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = discretize(next_state)\n",
    "            agent.learn(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "\n",
    "train(agent, env)\n",
    "\n",
    "# Q-learning agent definition\n",
    "class QLearningAgent:\n",
    "    def __init__(self, n_actions, n_states, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.n_actions = n_actions\n",
    "        self.q_table = np.zeros((n_states, n_states, n_actions))\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state[0], state[1]])\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        predict = self.q_table[state[0], state[1], action]\n",
    "        target = reward + self.gamma * np.max(self.q_table[next_state[0], next_state[1]])\n",
    "        self.q_table[state[0], state[1], action] += self.alpha * (target - predict)\n",
    "\n",
    "# Discretize the environment\n",
    "def discretize(state, bins=50):\n",
    "    return tuple((np.array(state) * bins // 500).astype(int))\n",
    "\n",
    "class RectangleMoveEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(RectangleMoveEnv, self).__init__()\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Let's assume action space is discrete: 0: Up, 1: Down, 2: Left, 3: Right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # Define the observation space as the position of the rectangle. This is a simplification.\n",
    "        # You can expand this to include more features if needed.\n",
    "        self.observation_space = spaces.Box(low=0, high=500, shape=(2,), dtype=float)  # Assuming canvas size of 500x500 for illustration\n",
    "\n",
    "    def reset(self):\n",
    "        # For simplicity, reset will return the rectangle to the center of the canvas\n",
    "        # This can be expanded to communicate with Flask server to get an actual reset position\n",
    "        return [250, 250]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Translate the action to the parameters of move_rectangle function\n",
    "        # For simplicity, let's assume fixed speed, distance, and angle based on the action\n",
    "        mappings = {\n",
    "            0: {'speed': 50, 'angle': 0, 'distance': 10},   # Up\n",
    "            1: {'speed': 50, 'angle': 180, 'distance': 10}, # Down\n",
    "            2: {'speed': 50, 'angle': 270, 'distance': 10}, # Left\n",
    "            3: {'speed': 50, 'angle': 90, 'distance': 10}   # Right\n",
    "        }\n",
    "\n",
    "        params = mappings[action]\n",
    "        response = requests.post('http://127.0.0.1:5000/move_rectangle', json=params)\n",
    "        data = response.json()\n",
    "\n",
    "        # Get the new position (state) from the data\n",
    "        new_position = [data['new_x'], data['new_y']]\n",
    "        \n",
    "        # Check border collision\n",
    "        border_hit_response = requests.get('http://127.0.0.1:5000/border_hit')\n",
    "        hit_data = border_hit_response.json()\n",
    "        done = hit_data['hit']\n",
    "\n",
    "        # Define reward. For simplicity, a negative reward if border is hit.\n",
    "        reward = -10 if done else 1\n",
    "\n",
    "        return new_position, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Optional method for visualization\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Initialize the Q-learning agent and the environment\n",
    "agent = QLearningAgent(n_actions=4, n_states=50)\n",
    "env = RectangleMoveEnv()\n",
    "\n",
    "# Train the agent on the environment\n",
    "def train(agent, env, episodes=1000):\n",
    "    for episode in range(episodes):\n",
    "        state = discretize(env.reset())\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = discretize(next_state)\n",
    "            agent.learn(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "\n",
    "train(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0e8457-9b3c-4645-9f5a-167b7f4c585a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mappings = {\n",
    "            0: {'speed': 50, 'angle': 0, 'distance': 10},   # Up\n",
    "            1: {'speed': 50, 'angle': 180, 'distance': 10}, # Down\n",
    "            2: {'speed': 50, 'angle': 270, 'distance': 10}, # Left\n",
    "            3: {'speed': 50, 'angle': 90, 'distance': 10}   # Right\n",
    "        }\n",
    "\n",
    "params = mappings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d1b482-6b46-4e2b-a954-c020ecf7b5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post('http://127.0.0.1:5000/move_rectangle', json=params)\n",
    "print(response.status_code)  # should be 200 for a successful response\n",
    "print(response.text)  # print the actual content of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c788a7-34fb-499e-ab70-428b0ffd583a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speed': 50, 'angle': 0, 'distance': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f189a1f-fc5d-4c26-b79e-989bc907affb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
